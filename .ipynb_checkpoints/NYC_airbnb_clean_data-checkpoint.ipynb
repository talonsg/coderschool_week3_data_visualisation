{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import math\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "\n",
    "#import geoplot as gplt\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pylab import *\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nyc_airbnb.csv')\n",
    "df2 = pd.read_csv('NYC_Citywide_Annualized_Calendar_Sales_Update.csv')\n",
    "geo_ny = gpd.read_file('./Individual_Landmark_Lots/Individual_Landmark_Lots.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10051\n",
       "reviews_per_month                 10051\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAN AIRBNB DATASET (df)\n",
    "\n",
    "#drop unused column\n",
    "df.drop(['host_name','host_id','name'], axis=1, inplace=True)\n",
    "\n",
    "#Only keep data with positive price\n",
    "df = df[df[\"price\"] > 0]\n",
    "\n",
    "#drop duplicate\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#check null data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\pandas\\core\\frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#EDIT/ADD COLUMNS TO AIRBNB DATASET (df)\n",
    "\n",
    "#add activity column\n",
    "#activity = No Record if no last review\n",
    "#activity = Inactive if last review is not within 1year of the latest last_review\n",
    "#activity = Active otherwise\n",
    "\n",
    "#convert to datetime\n",
    "\n",
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "time_threshold = pd.to_datetime('2018/12/06')\n",
    "\n",
    "df.loc[df['last_review'] >= time_threshold, 'activity'] = 'Active'\n",
    "df.loc[df['last_review'] < time_threshold, 'activity'] = 'Inactive'\n",
    "df.loc[df['last_review'].isnull(), 'activity'] = 'No Record'\n",
    "\n",
    "df_active = df.loc[df['activity'] == 'Active']\n",
    "df_active\n",
    "\n",
    "#add occupancy_% column\n",
    "df_active['occupancy_%'] = round(100 - df_active['availability_365']/ 365 * 100).astype('float')\n",
    "\n",
    "#reset index\n",
    "df_active.reset_index(inplace=True)\n",
    "df_active.drop(['index'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETERMINE ON AVERAGE HOW FAR AN AIRBNB FROM ALL THE LANDMARKS OF NYC\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    '''\n",
    "    function to calculated distance in km based on long and lat\n",
    "    '''\n",
    "    r = 6371\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))\n",
    "    return np.round(res, 2)\n",
    "\n",
    "def find_distance(df, df2):\n",
    "    how_far_list = []\n",
    "    for idx, item in df['coords'].iteritems():\n",
    "        distance_list = []\n",
    "        \n",
    "        for idx2, item2 in df2['coords'].iteritems():\n",
    "            #print(item, item2)\n",
    "            l = haversine_distance(item[1], item[0], item2[1], item2[0])\n",
    "            distance_list.append(l)\n",
    "            \n",
    "        mean_dist = mean(distance_list)   \n",
    "        how_far_list.append(mean_dist)\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "    return how_far_list\n",
    "\n",
    "   \n",
    "# geo_ny = geo_ny[['OBJECTID', 'geometry']]\n",
    "\n",
    "# geo_ny = geo_ny.to_crs(\"EPSG:4326\")  #convert to correct projection\n",
    "# geo_ny['coords'] = geo_ny['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# geo_ny['coords'] = [coords[0] for coords in geo_ny['coords']]\n",
    "\n",
    "# df_geo = df_active[['latitude','longitude']]\n",
    "# df_geo = gpd.GeoDataFrame(df_geo, geometry=gpd.points_from_xy(df_geo.longitude, df_geo.latitude))\n",
    "\n",
    "# df_geo['coords'] = df_geo['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# df_geo['coords'] = [coords[0] for coords in df_geo['coords']]\n",
    "\n",
    "\n",
    "# how_far_km = find_distance(df_geo, geo_ny)\n",
    "\n",
    "#save to csv so can import csv later to save time\n",
    "#how_far_df = pd.DataFrame(how_far_km, columns=[\"how_far_km\"])\n",
    "#how_far_df.to_csv('df_active_how_far_km2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read how_far_km_csv_file and add to df_active\n",
    "df3 = pd.read_csv('df_active_how_far_km.csv')\n",
    "df3\n",
    "\n",
    "df_active = pd.concat([df_active, df3], axis = 1)\n",
    "df_active.to_csv('clean_nyc_airbnb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN SALE_PRICE DATASET (df2)\n",
    "\n",
    "#drop unused column\n",
    "df2 = df2[['BOROUGH','BUILDING CLASS CATEGORY','NEIGHBORHOOD','SALE PRICE','SALE DATE','Latitude','Longitude']]\n",
    "\n",
    "#drop duplicate\n",
    "df2 = df2.drop_duplicates()\n",
    "\n",
    "#drop null data\n",
    "df2 = df2.dropna()\n",
    "\n",
    "#Rename borough\n",
    "\n",
    "df2.columns = ['neighbourhood_group','building_class','neighbourhood','sale_price','sale_date','latitude','longitude']\n",
    "\n",
    "df2['neighbourhood_group'] = df2['neighbourhood_group'].astype('str')\n",
    "\n",
    "df2['neighbourhood_group'].replace('1','Manhattan', inplace = True)\n",
    "df2['neighbourhood_group'].replace('2','Brooklyn', inplace = True)\n",
    "df2['neighbourhood_group'].replace('3','Queens', inplace = True)\n",
    "df2['neighbourhood_group'].replace('4','Bronx', inplace = True)\n",
    "df2['neighbourhood_group'].replace('5','Staten Island', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER OUT BUILDING CLASS (df2)\n",
    "\n",
    "airbnb_options = [\n",
    "    '01 ONE FAMILY DWELLINGS',\n",
    "    '02 TWO FAMILY DWELLINGS',\n",
    "    '10 COOPS - ELEVATOR APARTMENTS',\n",
    "    '13 CONDOS - ELEVATOR APARTMENTS',\n",
    "    '03 THREE FAMILY DWELLINGS',\n",
    "    '07 RENTALS - WALKUP APARTMENTS',\n",
    "    '09 COOPS - WALKUP APARTMENTS',\n",
    "    '04 TAX CLASS 1 CONDOS',\n",
    "    '15 CONDOS - 2-10 UNIT RESIDENTIAL',\n",
    "    '12 CONDOS - WALKUP APARTMENTS',\n",
    "    '17 CONDO COOPS',\n",
    "    '14 RENTALS - 4-10 UNIT',\n",
    "    '08 RENTALS - ELEVATOR APARTMENTS',\n",
    "    '16 CONDOS - 2-10 UNIT WITH COMMERCIAL UNIT'      \n",
    "]\n",
    "\n",
    "df2 = df2[df2['building_class'].isin(airbnb_options)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\pandas\\core\\frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#EDIT/ADD COLUMNS TO SALE_PRICE DATASET (df2)\n",
    "\n",
    "#convert to datetime\n",
    "df2['sale_date'] = pd.to_datetime(df2['sale_date'])\n",
    "\n",
    "lower_time_threshold = pd.to_datetime('2018/12/06')\n",
    "upper_time_threshold = pd.to_datetime('2019/12/06')\n",
    "\n",
    "df2 = df2.loc[df2['sale_date'] >= lower_time_threshold ]\n",
    "df_sale = df2.loc[df2['sale_date'] <= upper_time_threshold]\n",
    "\n",
    "#reset index\n",
    "df_sale.reset_index(inplace=True)\n",
    "df_sale.drop(['index'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #DETERMINE ON AVERAGE HOW FAR A SALE PROPERTY FROM ALL THE LANDMARKS OF NYC\n",
    "\n",
    "# geo_ny = geo_ny[['OBJECTID', 'geometry']]\n",
    "# geo_ny = geo_ny.to_crs(\"EPSG:4326\")  #convert to correct projection\n",
    "# geo_ny['coords'] = geo_ny['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# geo_ny['coords'] = [coords[0] for coords in geo_ny['coords']]\n",
    "\n",
    "# df_geo = df_sale[['latitude','longitude']]\n",
    "\n",
    "# df_geo = gpd.GeoDataFrame(df_geo, geometry=gpd.points_from_xy(df_geo.longitude, df_geo.latitude))\n",
    "# df_geo['coords'] = df_geo['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# df_geo['coords'] = [coords[0] for coords in df_geo['coords']]\n",
    "\n",
    "# how_far_km = find_distance(df_geo, geo_ny)\n",
    "\n",
    "# print(df_geo['coords'].count)\n",
    "# print(len(how_far_km))\n",
    "\n",
    "# #save to csv so can import csv later to save time\n",
    "# how_far_df = pd.DataFrame(how_far_km, columns=[\"how_far_km\"])\n",
    "# how_far_df.to_csv('df_sale_how_far_km2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv_file and add to df_active\n",
    "df4 = pd.read_csv('df_sale_how_far_km.csv')\n",
    "df4\n",
    "\n",
    "df_sale = pd.concat([df_sale, df4], axis = 1)\n",
    "df_sale.to_csv('clean_nyc_sale.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETERMINE THE MEDIAN PRICE OF EACH NEIGHBOURHOOD\n",
    "\n",
    "\n",
    "#Define a new neighbourhood column to compare with neighbourhood data from sale\n",
    "df_active['neigh_comp'] = df_active['neighbourhood'].str.upper()\n",
    "\n",
    "\n",
    "#rename neighbour hood to match sale data\n",
    "#some neighbourhood are not on the sale list, can assume name of nearby neighbourhood\n",
    "replace = [\n",
    "    ['CONCOURSE VILLAGE', 'CONCOURSE'],['WEST BRIGHTON', 'WEST NEW BRIGHTON'],\n",
    "    ['KEW GARDENS HILLS', 'KEW GARDENS'], ['BAY TERRACE, STATEN ISLAND', 'BAY TERRACE'],\n",
    "    ['WESTCHESTER SQUARE', 'WESTCHESTER'],[\"BULL'S HEAD\", 'BULLS HEAD'],\n",
    "    [\"NEW DORP BEACH\", 'NEW DORP-BEACH'],[\"BEDFORD-STUYVESANT\", 'BEDFORD STUYVESANT'],\n",
    "    [\"EAST HARLEM\", 'HARLEM-EAST'],[\"FLATIRON DISTRICT\", 'FLATIRON'],\n",
    "    [\"NORTH RIVERDALE\", 'RIVERDALE'],[\"EAST MORRISANIA\", 'MORRISANIA'],\n",
    "    [\"EAST FLATBUSH\", 'FLATBUSH-EAST'],[\"PRINCE'S BAY\", 'PRINCES BAY'],\n",
    "    [\"PRINCE'S BAY\", 'PRINCES BAY'],[\"FINANCIAL DISTRICT\", 'FINANCIAL'],\n",
    "    [\"SOUTH SLOPE\", 'PARK SLOPE SOUTH'],[\"HELL'S KITCHEN\", 'MIDTOWN WEST'],\n",
    "    [\"WEST VILLAGE\", 'GREENWICH VILLAGE'],['NOLITA','LITTLE ITALY'],\n",
    "    ['PROSPECT-LEFFERTS GARDENS','PROSPECT HEIGHTS'],['ROCKAWAY BEACH','ROCKAWAY PARK'],\n",
    "    ['BAYSWATER','FAR ROCKAWAY'], ['EASTCHESTER', 'WESTCHESTER'],\n",
    "    ['DITMARS STEINWAY','ASTORIA'],['THEATER DISTRICT','MIDTOWN WEST'],\n",
    "    ['EDGEMERE','ROCKAWAY PARK'], ['COLUMBIA ST', 'LOWER EAST SIDE'],\n",
    "    ['BATTERY PARK CITY','FINANCIAL'],['TWO BRIDGES','SOUTHBRIDGE'],\n",
    "    ['STUYVESANT TOWN','GRAMERCY'],['UNIVERSITY HEIGHTS',\"KINGSBRIDGE HTS/UNIV HTS\"],\n",
    "    ['MARBLE HILL', 'KINGSBRIDGE/JEROME PARK'],['NOHO','EAST VILLAGE'],\n",
    "    ['RANDALL MANOR','WEST NEW BRIGHTON'],['GRANITEVILLE','MARINERS HARBOR'],\n",
    "    ['HOWLAND HOOK','BLOOMFIELD'],['LIGHTHOUSE HILL','RICHMONDTOWN-LIGHTHS HILL'],\n",
    "    ['VINEGAR HILL','NAVY YARD'], ['DUMBO','DOWNTOWN-FULTON FERRY'],\n",
    "    ['SEA GATE', 'CONEY ISLAND'],['DOWNTOWN BROOKLYN','DOWNTOWN-FULTON MALL'],\n",
    "    ['FORT HAMILTON','DYKER HEIGHTS'],['OLINVILLE', 'WILLIAMSBRIDGE'],\n",
    "    ['CLAREMONT','VILLAGE MORRISANIA'], ['ALLERTON','PELHAM PARKWAY NORTH'],\n",
    "    ['SPUYTEN DUYVIL','RIVERDALE'],['EDENWALD','WESTCHESTER'],\n",
    "    ['WEST FARMS','CROTONA PARK'],['CLASON POINT', 'SOUNDVIEW']   \n",
    "]\n",
    "\n",
    "for i in replace:\n",
    "    df['neigh_comp'] = df['neigh_comp'].str.replace(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETERMINE MEDIAN PRICE OF PROPERTY IN EACH NEIGHBOURHOOD\n",
    "\n",
    "\n",
    "neighbour_list = df['neigh_comp'].to_list()\n",
    "neighbour_list = set(neighbour_list)\n",
    "neighbour_dict = {}\n",
    "\n",
    "for item in neighbour_list:       \n",
    "    temp_list = []\n",
    "    for index, row in df2.iterrows():\n",
    "        \n",
    "        if item in row['neighbourhood']:\n",
    "            price = row['sale_price']\n",
    "            temp_list.append(price)\n",
    "            \n",
    "    neighbour_dict[item]= temp_list\n",
    "    if len(temp_list) == 0:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "title = \"\"\n",
    "sns.catplot(x='neighbourhood_group', kind=\"count\", hue=\"room_type\", data=df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
